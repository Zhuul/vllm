#!/bin/bash
# Check WSL2 GPU Setup for vLLM Development
# This script verifies NVIDIA GPU accessibility in WSL2 environment

set -e

echo "=== WSL2 GPU Check for vLLM Development ==="
echo "Verifying NVIDIA GPU accessibility and configuration"
echo ""

# Basic system info
echo "üñ•Ô∏è  System Information:"
echo "Kernel: $(uname -r)"
echo "Distribution: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)"
echo ""

# Check if running in WSL2
if [[ -f /proc/version ]] && grep -q "microsoft" /proc/version; then
    echo "‚úÖ Running in WSL2"
else
    echo "‚ùå Not running in WSL2"
    exit 1
fi

# Check NVIDIA driver
echo ""
echo "üéÆ NVIDIA Driver Check:"
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ nvidia-smi available"
    nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv,noheader,nounits
    echo ""
    echo "GPU Devices:"
    nvidia-smi -L
else
    echo "‚ùå nvidia-smi not found"
    echo "Install NVIDIA drivers on Windows host"
fi

# Check CUDA installation
echo ""
echo "üöÄ CUDA Installation Check:"
if command -v nvcc &> /dev/null; then
    echo "‚úÖ nvcc available"
    nvcc --version | grep "release"
else
    echo "‚ö†Ô∏è  nvcc not found (may be normal if using container CUDA)"
fi

# Check CUDA libraries
echo ""
echo "üìö CUDA Libraries Check:"
WSL_NVIDIA_PATHS=(
    "/usr/lib/wsl/drivers"
    "/usr/lib/wsl/lib"
    "/usr/lib/x86_64-linux-gnu"
    "/usr/local/cuda/lib64"
)

FOUND_LIBS=()
for path in "${WSL_NVIDIA_PATHS[@]}"; do
    if [[ -d "$path" ]]; then
        LIBS=$(find "$path" -name "libcuda.so*" 2>/dev/null | head -3)
        if [[ -n "$LIBS" ]]; then
            echo "‚úÖ Found CUDA libraries in $path:"
            echo "$LIBS" | sed 's/^/   /'
            FOUND_LIBS+=("$path")
        fi
    fi
done

if [[ ${#FOUND_LIBS[@]} -eq 0 ]]; then
    echo "‚ùå No CUDA libraries found"
else
    echo ""
    echo "Library paths with CUDA: ${FOUND_LIBS[*]}"
fi

# Check NVIDIA Container Toolkit
echo ""
echo "üê≥ NVIDIA Container Toolkit Check:"
if command -v nvidia-ctk &> /dev/null; then
    echo "‚úÖ nvidia-ctk available"
    echo "Version: $(nvidia-ctk --version)"
    
    # Check CDI configuration
    if [[ -f /etc/cdi/nvidia.yaml ]]; then
        echo "‚úÖ CDI configuration exists"
        echo "Available devices:"
        nvidia-ctk cdi list 2>/dev/null | head -5 || echo "   (CDI list failed)"
    else
        echo "‚ö†Ô∏è  CDI configuration missing"
        echo "Run: sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml"
    fi
else
    echo "‚ùå nvidia-ctk not found"
    echo "Install NVIDIA Container Toolkit"
fi

# Check Podman
echo ""
echo "üê≥ Podman Check:"
if command -v podman &> /dev/null; then
    echo "‚úÖ Podman available"
    echo "Version: $(podman --version)"
    
    if podman info &>/dev/null; then
        echo "‚úÖ Podman daemon accessible"
        
        # Test GPU device access
        echo "Testing GPU device access..."
        if podman run --rm --device nvidia.com/gpu=all --security-opt=label=disable \
           nvidia/cuda:12.0-base-ubuntu20.04 nvidia-smi -L 2>/dev/null; then
            echo "‚úÖ GPU device access working!"
        else
            echo "‚ö†Ô∏è  GPU device access failed"
            echo "This may be due to missing CDI configuration or container issues"
        fi
    else
        echo "‚ö†Ô∏è  Podman daemon not accessible"
        echo "Try: podman machine start"
    fi
else
    echo "‚ùå Podman not found"
fi

# Check Python/PyTorch if available
echo ""
echo "üêç Python/PyTorch Check:"
if command -v python3 &> /dev/null; then
    echo "‚úÖ Python3 available: $(python3 --version)"
    
    # Check if PyTorch is available
    if python3 -c "import torch" 2>/dev/null; then
        echo "‚úÖ PyTorch available"
        TORCH_VERSION=$(python3 -c "import torch; print(torch.__version__)" 2>/dev/null)
        echo "PyTorch version: $TORCH_VERSION"
        
        # Check CUDA availability in PyTorch
        CUDA_AVAILABLE=$(python3 -c "import torch; print(torch.cuda.is_available())" 2>/dev/null)
        CUDA_COUNT=$(python3 -c "import torch; print(torch.cuda.device_count())" 2>/dev/null)
        
        if [[ "$CUDA_AVAILABLE" == "True" ]]; then
            echo "‚úÖ PyTorch CUDA available"
            echo "CUDA devices: $CUDA_COUNT"
            python3 -c "import torch; print('CUDA version:', torch.version.cuda)" 2>/dev/null
        else
            echo "‚ùå PyTorch CUDA not available"
            echo "This is the main issue - PyTorch cannot access CUDA runtime"
        fi
    else
        echo "‚ö†Ô∏è  PyTorch not available"
    fi
else
    echo "‚ö†Ô∏è  Python3 not found"
fi

# Environment variables check
echo ""
echo "üåç Environment Variables:"
echo "CUDA_HOME: ${CUDA_HOME:-'not set'}"
echo "PATH: ${PATH}"
echo "LD_LIBRARY_PATH: ${LD_LIBRARY_PATH:-'not set'}"
echo "NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES:-'not set'}"

# Summary
echo ""
echo "üìä Summary:"
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ NVIDIA drivers working"
else
    echo "‚ùå NVIDIA drivers issue"
fi

if [[ ${#FOUND_LIBS[@]} -gt 0 ]]; then
    echo "‚úÖ CUDA libraries found"
else
    echo "‚ùå CUDA libraries missing"
fi

if command -v nvidia-ctk &> /dev/null && [[ -f /etc/cdi/nvidia.yaml ]]; then
    echo "‚úÖ Container toolkit configured"
else
    echo "‚ùå Container toolkit needs setup"
fi

if command -v podman &> /dev/null && podman info &>/dev/null; then
    echo "‚úÖ Podman working"
else
    echo "‚ùå Podman needs setup"
fi

echo ""
echo "üí° Recommendations:"
echo "1. If PyTorch CUDA is not available, restart container with proper GPU mounts"
echo "2. Ensure LD_LIBRARY_PATH includes WSL NVIDIA paths"
echo "3. Use --device nvidia.com/gpu=all when running containers"
echo "4. Check container has proper CUDA environment variables"
echo ""
